{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "process.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "308f34cdc20740a9a7a6753a607c13bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_52c80329c11644eb89858a898cef6f1e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7260e324e6484b30b9df3e636cd30d71",
              "IPY_MODEL_11c89344126b42b1af81662a440c6f2e"
            ]
          }
        },
        "52c80329c11644eb89858a898cef6f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7260e324e6484b30b9df3e636cd30d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed52591f76a84eb3b9e0f482824d96b5",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f7c553a28a046de9f7aacca9b2dae5d"
          }
        },
        "11c89344126b42b1af81662a440c6f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d96bdb3f6b7b45d396ec5f3cefc2e1d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/25 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c310001a6d134c999fc4985fe2162634"
          }
        },
        "ed52591f76a84eb3b9e0f482824d96b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f7c553a28a046de9f7aacca9b2dae5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d96bdb3f6b7b45d396ec5f3cefc2e1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c310001a6d134c999fc4985fe2162634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le4oXBJrCbNW",
        "colab_type": "code",
        "outputId": "0819bf22-a517-44bf-9705-30855706123e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRZvPAhsCqjA",
        "colab_type": "code",
        "outputId": "643686e4-2fd0-4654-94b8-abb4b004f462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/drive/My Drive/NLP/SA_SSTdata"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/NLP/SA_SSTdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KpQepjwHXbh",
        "colab_type": "code",
        "outputId": "c588ee94-7818-4558-f6ef-713547bc73ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "pip install pytreebank"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytreebank\n",
            "  Downloading https://files.pythonhosted.org/packages/e0/12/626ead6f6c0a0a9617396796b965961e9dfa5e78b36c17a81ea4c43554b1/pytreebank-0.2.7.tar.gz\n",
            "Building wheels for collected packages: pytreebank\n",
            "  Building wheel for pytreebank (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytreebank: filename=pytreebank-0.2.7-cp36-none-any.whl size=37072 sha256=569df8e9e2fe67c063852bce05afa2976d4313a9474835ffc83d642719e26ce4\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/b6/91/e9edcdbf464f623628d5c3aa9de28888c726e270b9a29f2368\n",
            "Successfully built pytreebank\n",
            "Installing collected packages: pytreebank\n",
            "Successfully installed pytreebank-0.2.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxR6lKIcCQQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pytreebank\n",
        "dataset = pytreebank.load_sst()\n",
        "example = dataset[\"train\"][0]\n",
        "\n",
        "# extract spans from the tree.\n",
        "for label, sentence in example.to_labeled_lines():\n",
        "\tprint(\"%s has sentiment label %s\" % (\n",
        "\t\tsentence,\n",
        "\t\t[\"very negative\", \"negative\", \"neutral\", \"positive\", \"very positive\"][label]\n",
        "\t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS7RfJ5uIxJM",
        "colab_type": "code",
        "outputId": "e96ab599-49b6-4aa7-da60-acd45dc7475e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Load data\n",
        "import pytreebank\n",
        "import sys\n",
        "import os\n",
        "\n",
        "out_path = os.path.join(sys.path[0], 'sst_{}.txt')\n",
        "dataset = pytreebank.load_sst('./raw_data')\n",
        "\n",
        "# Store train, dev and test in separate files\n",
        "for category in ['train', 'test', 'dev']:\n",
        "    with open(out_path.format(category), 'w') as outfile:\n",
        "        for item in dataset[category]:\n",
        "            outfile.write(\"__label__{}\\t{}\\n\".format(\n",
        "                item.to_labeled_lines()[0][0] + 1,\n",
        "                item.to_labeled_lines()[0][1]\n",
        "            ))\n",
        "# Print the length of the training set\n",
        "print(len(dataset['train']))\n",
        "# Print the length of the training set\n",
        "print(len(dataset['test']))\n",
        "# Print the length of the training set\n",
        "print(len(dataset['dev']))\n",
        "a = len(dataset['train']) + len(dataset['dev']) + len(dataset['test'])\n",
        "print(a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8544\n",
            "2210\n",
            "1101\n",
            "11855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lh5ICvkBJtpE",
        "colab_type": "code",
        "outputId": "0acb3030-b31b-494a-e6c8-87efd7f4fb14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Read train data\n",
        "df = pd.read_csv('sst_train.txt', sep='\\t', header=None, names=['truth', 'text'])\n",
        "\n",
        "ax = df['truth'].value_counts(sort=False).plot(kind='barh')\n",
        "ax.set_xlabel(\"Number of Samples in training Set\")\n",
        "ax.set_ylabel(\"Label\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Label')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaQAAAEGCAYAAAAqmOHQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAZqUlEQVR4nO3df7jmdV3n8eeLYURpdESYWMScITUw1JCZ2nCNZGktxQ1pp1LYRSojE9dq1xIvvUq7wqCW8hIXDBOxZXarteXCYpNwSkzK8EADA8Io2aAiiVgNkPLDmff+8f2c9eZwZs7vuT8z5/m4rvu6v+fz/fX+fs995jWfz/29v3eqCkmSxu2AcRcgSRIYSJKkThhIkqQuGEiSpC4YSJKkLhw47gL2ZYcddlitW7du3GVI0j7lxhtvvK+q1kxtN5AWYN26dUxMTIy7DEnapyS5a7p2h+wkSV0wkCRJXTCQJEldMJAkSV0wkCRJXTCQJEldMJAkSV0wkCRJXTCQJEld8E4NC7D17h2sO/fqcZchSXvV9vNPWZLt2kOSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdWHsgZTkwRnmr0ty6xy3eXmSjfOs590z1SRJWnxjD6SeJNkAHDLuOiRpOeomkJKsSrI5yU1JtiY5dWT2gUk2Jbk9yYeSHNzWWZ/kuiQ3JrkmyREL2P8K4DeBX5phubOTTCSZ2Pm1HfPdnSRpim4CCXgIOK2qjgdOAi5MkjbvaODiqnoucD/w+iQrgYuAjVW1HrgMOG8B+38D8OGqumdPC1XVpVW1oao2rDh49QJ2J0ka1dPNVQO8M8mJwC7gSODwNu8LVXV9m74CeCPwEeB5wLUtt1YAewyT3e44eTrwo8BL5lu8JGlhegqkM4A1wPqqejTJduCJbV5NWbYYAuy2qjphEfb9QuDZwJ0t3A5OcmdVPXsRti1JmoWehuxWA/e2MDoJWDsy75lJJoPndOATwDZgzWR7kpVJjp3Pjqvq6qr6V1W1rqrWAV8zjCRp7+opkDYBG5JsBc4E7hiZtw04J8ntDFfBXVJVjwAbgQuS3AxsAV60l2uWJC2SsQ/ZVdWq9nwfsLvht2N2s+4W4MRp2s9ajJokSXtPTz0kSdIytiQ9pCSHAptHmlYAO0eeJ51cVV9dihpaHVcCR01pXgvcNaXtzVV1zVLVIUma2ZIEUguZ45Zi23Os47Rx1yBJmh2H7CRJXRj7RQ37sucfuZqJ808ZdxmStF+whyRJ6oKBJEnqgoEkSeqCgSRJ6oKBJEnqgoEkSeqCgSRJ6oKBJEnqgoEkSeqCgSRJ6oKBJEnqgoEkSeqCgSRJ6oKBJEnqgoEkSeqCgSRJ6oKBJEnqgoEkSeqCgSRJ6oKBJEnqgoEkSerCgeMuYF+29e4drDv36nGXIS07288/ZdwlaAnYQ5IkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdWHsgZTkwRnmr0ty6xy3eXmSjXNc5/1Jbk5yS5IPJVk1l/UlSQsz9kDqyC9U1XdV1QuAzwNvGHdBkrScdBNISVYl2ZzkpiRbk5w6MvvAJJuS3N56Lwe3ddYnuS7JjUmuSXLEfPdfVfe3bQZ4ElALOiBJ0px0E0jAQ8BpVXU8cBJwYQsHgKOBi6vqucD9wOuTrAQuAjZW1XrgMuC8hRSQ5APAPwDHtG1Pt8zZSSaSTOz82o6F7E6SNKKnQArwziS3AB8FjgQOb/O+UFXXt+krgBczhNTzgGuTbAHeBjxjIQVU1U8ATwduB358N8tcWlUbqmrDioNXL2R3kqQRPd1c9QxgDbC+qh5Nsh14Yps3dfisGALstqo6YTGLqKqdSX4f+CXgA4u5bUnS7vXUQ1oN3NvC6CRg7ci8ZyaZDJ7TgU8A24A1k+1JViY5dj47zuDZk9PADwN3zPM4JEnz0FMgbQI2JNkKnMljA2EbcE6S24FDgEuq6hFgI3BBkpuBLcCL5rnvAB9s+94KHAH86jy3JUmah7EP2VXVqvZ8H7C74bdjdrPuFuDEadrPmmMNu4B/M5d1JEmLq6cekiRpGVuSHlKSQ4HNI00rgJ0jz5NOrqqvLkUNrY4rgaOmNK8F7prS9uaqumap6pAkzWxJAqmFzHFLse051nHauGuQJM2OQ3aSpC6M/aKGfdnzj1zNxPmnjLsMSdov2EOSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR14cBxF7Av23r3Dtade/W4y5Dmbfv5p4y7BOn/22MgJXkAqMkf23O16aqqpyxhbZKkZWSPgVRVT95bhUiSlrdZv4eU5MVJfqJNH5bkqKUrS5K03MwqkJL8CvBm4C2t6QnAFUtVlCRp+ZltD+k04IeBfwGoqi8BDudJkhbNbAPpkaoq2gUOSb5l6UqSJC1Hsw2kP0zyO8BTk/w08FHgfUtXliRpuZnV55Cq6r8l+XfA/cB3AL9cVdcuaWWSpGVlLndq2Ar8JfDxNr0okjw4w/x1SW6d4zYvT7JxHuv8fZIt7XHcXNaXJC3MbK+yey1wA/AjwEbgk0l+cikLG5NfrKrj2mPLuIuRpOVktrcO+kXghVX1VYAkhwJ/BVy2WIUkWQVcBRwCrATeVlVXTdaZZBNwPHAbcGZVfS3JeuC3gFXAfcBZVXXPYtW0mzrPBs4GWPGUNUu5K0laVmY7ZPdV4IGRnx9obYvpIeC0qjoeOAm4MMnk7YqOBi6uqucyvI/1+iQrgYuAjVW1niEcz1tgDecluSXJbyc5aLoFqurSqtpQVRtWHLx6gbuTJE2a6V52/6VN3gn8TZKrGC79PhW4ZZFrCfDOJCcCu4AjgcPbvC9U1fVt+grgjcBHgOcB17bcWgEspHf0FuAfGD70eynDB4F/dQHbkyTNwUxDdpMffv279ph01TTLLtQZwBpgfVU9mmQ78MQ2r6YsO3mD19uq6oTF2PnIUN/DST4AvGkxtitJmp2Zbq76jr1VCLAauLeF0UnA2pF5z0xyQlX9NXA68AlgG7Bmsr0N4X1HVd02n50nOaKq7mnDhK8E5nRlnyRpYWZ1UUOSNcAvAcfyzV4LVfVvF7GWTcAfJ9kKTAB3jMzbBpyT5DLg08AlVfVIu7T73UlWMxzLuxguepjX/ttxBtgCvG6e25EkzcNsr7LbBPwB8AqGf6hfA3xlMQqoqlXt+T5gd8Nvx+xm3S3AidO0nzWPOhYzXCVJczTbq+wOrar3A49W1XVV9ZOA/4BLkhbNbHtIj7bne5KcAnwJeNruFm6fU9o80rQC2DnyPOnkyc82LYUkVwJTv7dpLXDXlLY3V9U1S1WHJGlmsw2kX2vv0/xXhs/+PAX4+d0t3EJm7LfeqarTxl2DJGl2Zntz1T9pkzsYPrRKkt0GkiRJc5Xha47msWLy+ap65iLXs0/ZsGFDTUxMjLsMSdqnJLmxqjZMbZ/L3b4ft80FrCtJ0mMsJJDm17WSJGkaM93L7gGmD54AT1qSiiRJy9JMtw568p7mS5K0WBYyZCdJ0qIxkCRJXTCQJEldMJAkSV0wkCRJXTCQJEldMJAkSV0wkCRJXTCQJEldMJAkSV0wkCRJXTCQJEldMJAkSV0wkCRJXTCQJEldMJAkSV0wkCRJXdjjN8Zqz7bevYN151497jK0n9l+/injLkEaC3tIkqQuGEiSpC4YSJKkLhhIkqQuGEiSpC4YSJKkLhhIkqQujD2Qkjw4w/x1SW6d4zYvT7Jxjuu8IcmdSSrJYXNZV5K0cGMPpI5cD/wAcNe4C5Gk5aibQEqyKsnmJDcl2Zrk1JHZBybZlOT2JB9KcnBbZ32S65LcmOSaJEfMd/9V9bdVtX2hxyFJmp9uAgl4CDitqo4HTgIuTJI272jg4qp6LnA/8PokK4GLgI1VtR64DDhvqYtMcnaSiSQTO7+2Y6l3J0nLRk/3sgvwziQnAruAI4HD27wvVNX1bfoK4I3AR4DnAde23FoB3LPURVbVpcClAAcd8Zxa6v1J0nLRUyCdAawB1lfVo0m2A09s86b+w18MAXZbVZ2w90qUJC2VnobsVgP3tjA6CVg7Mu+ZSSaD53TgE8A2YM1ke5KVSY7dqxVLkhZNT4G0CdiQZCtwJnDHyLxtwDlJbgcOAS6pqkeAjcAFSW4GtgAvmu/Ok7wxyReBZwC3JPnd+W5LkjR3Yx+yq6pV7fk+YHfDb8fsZt0twInTtJ81jzreDbx7rutJkhZHTz0kSdIytiQ9pCSHAptHmlYAO0eeJ51cVV9dihpaHVcCR01pXsvjP/z65qq6ZqnqkCTNbEkCqYXMcUux7TnWcdq4a5AkzY5DdpKkLoz9ooZ92fOPXM3E+aeMuwxJ2i/YQ5IkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXBQJIkdcFAkiR1wUCSJHXhwHEXsC/bevcO1p179bjLkKQ5237+KeMu4XHsIUmSumAgSZK6YCBJkrpgIEmSumAgSZK6YCBJkrpgIEmSumAgSZK6MPZASvLgDPPXJbl1jtu8PMnGOa6zKcm2JLcmuSzJyrmsL0lamLEHUkc2AccAzweeBLx2vOVI0vLSTSAlWZVkc5KbkmxNcurI7ANbD+b2JB9KcnBbZ32S65LcmOSaJEfMd/9V9X+rAW4AnrGbOs9OMpFkYufXdsx3d5KkKboJJOAh4LSqOh44CbgwSdq8o4GLq+q5wP3A69uQ2kXAxqpaD1wGnLfQItp2/xPwkenmV9WlVbWhqjasOHj1QncnSWp6urlqgHcmORHYBRwJHN7mfaGqrm/TVwBvZAiM5wHXttxaAdyzCHVcDHy8qv5yEbYlSZqlngLpDGANsL6qHk2yHXhim1dTli2GALutqk5YrAKS/Eqr4WcWa5uSpNnpachuNXBvC6OTgLUj856ZZDJ4Tgc+AWwD1ky2J1mZ5Nj57jzJa4EfBF5dVbvmux1J0vz0FEibgA1JtgJnAneMzNsGnJPkduAQ4JKqegTYCFyQ5GZgC/CiBez/vQxDhH+dZEuSX17AtiRJczT2IbuqWtWe7wN2N/x2zG7W3QKcOE37WfOoY+znQpKWs556SJKkZWxJegVJDgU2jzStAHaOPE86uaq+uhQ1tDquBI6a0rwWuGtK25ur6pqlqkOSNLMlCaQWMsctxbbnWMdp465BkjQ7DtlJkrrgG/kL8PwjVzNx/injLkOS9gv2kCRJXTCQJEldMJAkSV0wkCRJXTCQJEldMJAkSV0wkCRJXTCQJEldMJAkSV0wkCRJXUjV1G8H12wleYDhywM1OAy4b9xFdMZz8niek8dajudjbVWtmdrovewWZltVbRh3Eb1IMuH5eCzPyeN5Th7L8/FNDtlJkrpgIEmSumAgLcyl4y6gM56Px/OcPJ7n5LE8H40XNUiSumAPSZLUBQNJktQFA2kekvxQkm1J7kxy7rjr2ZuSbE+yNcmWJBOt7WlJrk3y2fZ8SGtPkne383RLkuPHW/3iSHJZknuT3DrSNudzkOQ1bfnPJnnNOI5lMezmfLw9yd3tdbIlyctH5r2lnY9tSX5wpH2/+btK8m1J/iLJp5PcluTnWvuyfZ3MSlX5mMMDWAH8HfDtwBOAm4HvHHdde/H4twOHTWn7DeDcNn0ucEGbfjnwp0CA7wX+Ztz1L9I5OBE4Hrh1vucAeBrwufZ8SJs+ZNzHtojn4+3Am6ZZ9jvb38xBwFHtb2nF/vZ3BRwBHN+mnwx8ph37sn2dzOZhD2nuvge4s6o+V1WPAL8PnDrmmsbtVOCDbfqDwCtH2n+vBp8EnprkiHEUuJiq6uPAP05pnus5+EHg2qr6x6r6J+Ba4IeWvvrFt5vzsTunAr9fVQ9X1d8DdzL8Te1Xf1dVdU9V3dSmHwBuB45kGb9OZsNAmrsjgS+M/PzF1rZcFPBnSW5McnZrO7yq7mnT/wAc3qaX07ma6zlYDufmDW346bLJoSmW4flIsg54IfA3+DrZIwNJc/XiqjoeeBlwTpITR2fWMM6wrD9L4DkA4BLgWcBxwD3AheMtZzySrAL+CPj5qrp/dJ6vk8czkObubuDbRn5+RmtbFqrq7vZ8L3Alw1DLlyeH4trzvW3x5XSu5noO9utzU1VfrqqdVbULeB/D6wSW0flIspIhjDZV1f9pzb5O9sBAmrtPAc9JclSSJwCvAj485pr2iiTfkuTJk9PAS4FbGY5/8uqf1wBXtekPA2e2K4i+F9gxMlyxv5nrObgGeGmSQ9pw1ktb235hynuFpzG8TmA4H69KclCSo4DnADewn/1dJQnwfuD2qvqtkVm+TvZk3FdV7IsPhitiPsNwVdBbx13PXjzub2e4+ulm4LbJYwcOBTYDnwU+CjyttQf47+08bQU2jPsYFuk8/C+GYahHGcb0f2o+5wD4SYY39e8EfmLcx7XI5+N/tOO9heEf2yNGln9rOx/bgJeNtO83f1fAixmG424BtrTHy5fz62Q2D28dJEnqgkN2kqQuGEiSpC4YSJKkLhhIkqQuGEiSpC4YSBq7JJXkwpGf35Tk7Yu07cuTbFyMbc2wnx9NcnuSv5jSfkC7i/OtGe6S/qn2+ZulrGV7ksMWuI3XJTlzDsuvS3L6PPf1V7NY5neTfOd8tj/Ntt7a7sB9S7sT+b+eYfmzkjx9MfatPTtw3AVIwMPAjyT59aq6b9zFTEpyYFV9Y5aL/xTw01X1iSntPw48HXhBVe1K8gzgXxazzqVQVe+d4yrrgNOB/zl1xkznsapeNIt6XjvHeqaV5ATgFQx34n64BfcTZljtLIYP9n5pMWrQ7tlDUg++AVwK/MLUGVN7OEkebM8vSXJdkquSfC7J+UnOSHJD64k8a2QzP5BkIslnkryirb8iyW+2HsstSX5mZLt/meTDwKenqefVbfu3Jrmgtf0ywwch35/kN6escgRwTw230KGqvljDXZtJckmr67Yk7xjZx/Ykv97+9z6R5Pgk1yT5uySvG6nz40muzvAdQu9N8ri/5yT/sZ2TLUl+px33inZeJ3tt0533tyd5U5v+WJIL2nY+k+T7Hv8r5Hzg+9p+fqH1Kj6c5M+BzUlWJdmc5Ka2z1NH9jX6O/1Ykg8luSPJpnbHg8kaNkwun+S8JDcn+WSSw1v7s9rPW5P82uR2p/l93FdVD7ffx31V9aW2/vr2mrqxne8j2mtvA7CpHduTptmmFsu4P5nrwwfwIPAUhu9aWg28CXh7m3c5sHF02fb8EuCfGf6BOYjh/l7vaPN+DnjXyPofYfjP13MY7iTwROBs4G1tmYOACYbv53kJQw/mqGnqfDrweWANw+jCnwOvbPM+xjR3omC499h2hk/qXwi8cGTe5Kf0V7T1X9B+3g78bJv+bYZP+z+57ffLI8f/EMPdM1YwfC3BxpH1DwOeC/wxsLK1XwycCaxn+EqDyTqeOk3db6d9n1Gr7cI2/XLgo9Ms/xLgT0Z+Pqud68ljPBB4Sps+jOGuA5MfzB/9ne5o5+wA4K8Zbub7mPPLcAeEf9+mf2Pk9/gnwKvb9OsmtzulzlXtd/GZdj6+v7WvBP4KWNN+/nHgsj39bn0s/sMekrpQw52Qfw944xxW+1QN3zvzMMMtV/6stW9lGEKa9IdVtauqPsvwBWfHMNwT7MwkWxi+FuBQhsACuKGG7+qZ6ruBj1XVV2oYgtrE8OV0ezquLwJHA28BdjH0Fk5us38syU3A3wLHMnyB26TJ+7htZfiytgeq6ivAw0meOlLn56pqJ8Pte148ZfcnM4TPp9pxnswQYJ8Dvj3JRUl+CLifmU3eHPRGHntu9+Taqpr8nqQA70xyC8Mtc47km1+9MOqGGnqRuxiCY7p9PcIQPlPrOQH43236cUOHAFX1IMM5ORv4CvAHSc5i+B09D7i2nau3MQSj9iLfQ1JP3gXcBHxgpO0btKHlNiQ1Ot7/8Mj0rpGfd/HY1/bU+2MVwz+Q/7mqHnOjyiQvYZHf42mB+afAnyb5MvDKJJ9j6Al+d1X9U5LLGXpuk0aPZepxTh7bdMc1KsAHq+otU2tK8l0MX/72OuDHGO6XtieTNexk9v9ujJ7HMxh6eOur6tEk23ns8U7dz5729Wi1rssc6wGgBfjHgI8l2cpwk9Mbgduq6oS5bEuLyx6SutH+N/2HDBcITNrO8D9agB9mGFqZqx/NcLXbsxh6CNsY7pj8sxm+IoAk35HhDuZ7cgPw/UkOS7ICeDVw3Z5WaO//PL1NHwC8ALiLYYjyX4Ad7T2Ql83juL4nw92xD2AYYpp6QcVmYGOSb237f1qStRneyD+gqv6IoSdw/Dz2PdUDDMOKu7MauLeF0UnA2kXY51SfBP5Dm37VdAskOTrJc0aajmP4fWwD1mS46IEkK5Mc25aZ6di0SOwhqTcXAm8Y+fl9wFVJbmZ4L2g+vZfPM4TJU4DXVdVDSX6XYajnpvbG+Vf45tdJT6uq7klyLvAXDL2Pq6vqqj2tA3wr8L4kB7WfbwDe02r4W+AOhm8EvX4ex/Up4D3As1tNV06p99NJ3sbwDb8HMNyN+xzg68AHRi6CeFwPah5uAXa239PlwD9Nmb8J+OPWI5lgOO7F9vPAFUneyvBa2THNMquAi9qw5zcY3ss6u6oeaRcwvDvJaoZ/G9/FcFf7y4H3Jvk6cEJVfX0Jahd4t29pX9SGFt9UVa8Ydy29SHIw8PWqqiSvYrjA4dSZ1lM/7CFJ2l+sB97Terz/zMzvi6kz9pAkSV3wogZJUhcMJElSFwwkSVIXDCRJUhcMJElSF/4fDTnebbOw+DgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky2LgYufKBG0",
        "colab_type": "code",
        "outputId": "769e0245-71fa-4bfb-d40a-ca5f9aae872c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "# Read train data\n",
        "df = pd.read_csv('../data/sst_train.txt', sep='\\t', header=None, names=['truth', 'text'])\n",
        "df['truth'] = df['truth'].str.replace('__label__', '')\n",
        "df['truth'] = df['truth'].astype(int).astype('category')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>truth</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Singer/composer Bryan Adams contributes a slew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>You 'd think by now America would have had eno...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Yet the act is still charming here .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  truth                                               text\n",
              "0     4  The Rock is destined to be the 21st Century 's...\n",
              "1     5  The gorgeously elaborate continuation of `` Th...\n",
              "2     4  Singer/composer Bryan Adams contributes a slew...\n",
              "3     3  You 'd think by now America would have had eno...\n",
              "4     4               Yet the act is still charming here ."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPREI3XnLvd9",
        "colab_type": "code",
        "outputId": "0ca0c7ae-87e8-4d1d-d5ed-55db7da651ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# Use NaiveBayes\n",
        "\n",
        "import torchtext\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from tqdm import tqdm\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self, text):\n",
        "        self.train_iter = train_iter\n",
        "        self.test_iter = test_iter\n",
        "        self.val_iter = val_iter\n",
        "        self.array_like = np.zeros((train_iter.batch_size, len(text.vocab)))\n",
        "        \n",
        "    def binarize_occurrences(self, indices):\n",
        "        occurrences = self.array_like.copy()\n",
        "        for idx, entry in enumerate(indices): occurrences[idx][entry] = 1\n",
        "        return occurrences\n",
        "\n",
        "    def batch_to_input(self, batch, train = True):\n",
        "        word_indices = batch.text.data.numpy().T\n",
        "        x = self.binarize_occurrences(word_indices)\n",
        "        if train:\n",
        "            y = batch.label.data.numpy()\n",
        "            return x, y\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def train_mnb(self, train_iter, val_iter, no_epochs):\n",
        "        self.model = MultinomialNB(alpha=1.0, fit_prior=True)\n",
        "        for epoch in tqdm(range(1, no_epochs+1)):\n",
        "            for batch in train_iter:\n",
        "                x, y = self.batch_to_input(batch, train = True)\n",
        "                self.model.partial_fit(x, y, classes = [1,2])\n",
        "            \n",
        "            if epoch % 1 == 0:\n",
        "                acc = self.validate(val_iter)\n",
        "                print('Epoch ', epoch, '| Validation Accuracy: ', acc)\n",
        "        print('Done training.')\n",
        "        \n",
        "    def test(self, test_iter):\n",
        "        \"All models should be able to be run with following command.\"\n",
        "        upload, trues = [], []\n",
        "\n",
        "        for batch in test_iter:\n",
        "            x, y = self.batch_to_input(batch, train = False), batch.label\n",
        "            probs = self.model.predict(x)\n",
        "            upload += list(probs)\n",
        "            trues += list(y.data)\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(upload, trues)])\n",
        "        accuracy = correct / len(trues)\n",
        "        print('Test Accuracy: ', accuracy)\n",
        "        \n",
        "        with open(\"predictions.txt\", \"w\") as f:\n",
        "            for u in upload:\n",
        "                f.write(str(u) + \"\\n\")\n",
        "                \n",
        "    def validate(self, val_iter):\n",
        "        y_p, y_t, correct = [], [], 0\n",
        "        for batch in val_iter:\n",
        "            x, y = self.batch_to_input(batch, train = False), batch.label\n",
        "            probs = self.model.predict(x)[:len(y.data)]\n",
        "            y_p += list(probs)\n",
        "            y_t += list(y.data)\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(y_p, y_t)])\n",
        "        accuracy = correct / len(y_p)\n",
        "        return accuracy\n",
        "\n",
        "text = torchtext.data.Field(include_lengths = False)\n",
        "label = torchtext.data.Field(sequential=False)\n",
        "train, val, test = torchtext.datasets.SST.splits(text, label, filter_pred=lambda ex: ex.label != 'neutral')\n",
        "text.build_vocab(train)\n",
        "label.build_vocab(train)\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=10, device=-1, repeat = False)\n",
        "mnb = NaiveBayes(text)\n",
        "mnb.train_mnb(train_iter, val_iter, 1)\n",
        "mnb.test(test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "100%|██████████| 1/1 [00:02<00:00,  2.15s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch  1 | Validation Accuracy:  0.7981651376146789\n",
            "Done training.\n",
            "Test Accuracy:  0.8209774848984075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOCThIuINyN9",
        "colab_type": "code",
        "outputId": "d2667047-f908-4643-a596-bb0fa61fa727",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#  Logistic Regression\n",
        "import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, batch_size):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes, bias = True)\n",
        "        self.array_like = np.zeros((batch_size, input_size))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        output = self.linear(x)\n",
        "        activated = nn.functional.sigmoid(output)\n",
        "        return activated\n",
        "\n",
        "    def predict(self, x):\n",
        "        output = self.forward(x)\n",
        "        logits = nn.functional.log_softmax(output, dim = 1)\n",
        "        return logits.max(1)[1] + 1\n",
        "\n",
        "    def binarize_occurrences(self, indices):\n",
        "        occurrences = self.array_like.copy()\n",
        "        for idx, entry in enumerate(indices): occurrences[idx][entry] = 1\n",
        "        return occurrences\n",
        "\n",
        "    def batch_to_input(self, batch, train = True):\n",
        "        word_indices = batch.text.data.numpy().T\n",
        "        x = self.binarize_occurrences(word_indices)\n",
        "        if train:\n",
        "            return Variable(torch.FloatTensor(x)), batch.label\n",
        "        else:\n",
        "            return Variable(torch.FloatTensor(x))\n",
        "    \n",
        "    def train(self, train_iter, val_iter, num_epochs, learning_rate = 1e-3, plot = False):\n",
        "        criterion = nn.NLLLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "        loss_vec = []\n",
        "        \n",
        "        for epoch in tqdm(range(1, num_epochs+1)):\n",
        "            epoch_loss = 0\n",
        "            for batch in train_iter:\n",
        "                x, y = self.batch_to_input(batch, train = True)\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                output = self.forward(x)\n",
        "                \n",
        "                loss = criterion(output, y-1)\n",
        "                loss.backward()\n",
        "                \n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.data\n",
        "            self.model = model\n",
        "            \n",
        "            loss_vec.append(epoch_loss / len(train_iter))\n",
        "            if epoch % 1 == 0:\n",
        "                acc = self.validate(val_iter)\n",
        "                print('Epoch {} loss: {} | Valid acc: {}'.format(epoch, loss_vec[epoch-1], acc))\n",
        "        if plot:\n",
        "            plt.plot(range(len(loss_vec)), loss_vec)\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "        print('\\nModel trained.\\n')\n",
        "        self.loss_vec = loss_vec\n",
        "\n",
        "    def test(self, test_iter):\n",
        "        \"All models should be able to be run with following command.\"\n",
        "        upload, trues = [], []\n",
        "        # Update: for kaggle the bucket iterator needs to have batch_size 10\n",
        "        for batch in test_iter:\n",
        "            # Your prediction data here (don't cheat!)\n",
        "            x, y = self.batch_to_input(batch, train = False), batch.label\n",
        "            preds = self.predict(x)\n",
        "            upload += list(preds.data.numpy())\n",
        "            trues += list(y.data.numpy())\n",
        "            \n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(upload, trues)])\n",
        "        accuracy = correct / len(trues)\n",
        "        print('Test Accuracy:', accuracy)\n",
        "        \n",
        "        with open(\"predictions.txt\", \"w\") as f:\n",
        "            for u in upload:\n",
        "                f.write(str(u) + \"\\n\")\n",
        "                \n",
        "    def validate(self, val_iter):\n",
        "        y_p, y_t, correct = [], [], 0\n",
        "        for batch in val_iter:\n",
        "            x, y = self.batch_to_input(batch, train = False), batch.label\n",
        "            probs = self.model.predict(x)[:len(y.data.numpy())]\n",
        "            y_p += list(probs.data.numpy())\n",
        "            y_t += list(y.data.numpy())\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(y_p, y_t)])\n",
        "        accuracy = correct / len(y_p)\n",
        "        return accuracy\n",
        "\n",
        "\n",
        "text = torchtext.data.Field(include_lengths = False)\n",
        "label = torchtext.data.Field(sequential=False)\n",
        "train, val, test = torchtext.datasets.SST.splits(text, label, filter_pred=lambda ex: ex.label != 'neutral')\n",
        "text.build_vocab(train)\n",
        "label.build_vocab(train)\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=10, device=-1, repeat = False)\n",
        "\n",
        "model = LogisticRegression(len(text.vocab), 2, 10)\n",
        "model.train(train_iter = train_iter, val_iter = val_iter, num_epochs = 11 , learning_rate = 1e-3, plot = False)\n",
        "model.test(test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "  0%|          | 0/11 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "  9%|▉         | 1/11 [00:01<00:13,  1.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 loss: -0.8369014263153076 | Valid acc: 0.7052752293577982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 18%|█▊        | 2/11 [00:02<00:13,  1.45s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 loss: -0.9692325592041016 | Valid acc: 0.7431192660550459\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 3/11 [00:04<00:12,  1.51s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 loss: -0.9858507513999939 | Valid acc: 0.7568807339449541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▋      | 4/11 [00:06<00:10,  1.53s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 loss: -0.9919400811195374 | Valid acc: 0.7557339449541285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 5/11 [00:07<00:09,  1.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 loss: -0.9949523210525513 | Valid acc: 0.7580275229357798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▍    | 6/11 [00:09<00:07,  1.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 loss: -0.9966669082641602 | Valid acc: 0.7637614678899083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▎   | 7/11 [00:11<00:06,  1.59s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 loss: -0.9977269768714905 | Valid acc: 0.768348623853211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 73%|███████▎  | 8/11 [00:12<00:04,  1.60s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 loss: -0.9984187483787537 | Valid acc: 0.7649082568807339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 82%|████████▏ | 9/11 [00:14<00:03,  1.62s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 loss: -0.9988841414451599 | Valid acc: 0.7672018348623854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 91%|█████████ | 10/11 [00:16<00:01,  1.64s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 loss: -0.9992055892944336 | Valid acc: 0.768348623853211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 11/11 [00:17<00:00,  1.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11 loss: -0.9994297027587891 | Valid acc: 0.7729357798165137\n",
            "\n",
            "Model trained.\n",
            "\n",
            "Test Accuracy: 0.7666117517847336\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_7ESeKCF4MC",
        "colab_type": "code",
        "outputId": "0928e784-4a98-4187-fb05-5ebccadfb226",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchtext.vocab import Vectors\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CBoW(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, batch_size):\n",
        "        super(CBoW, self).__init__()\n",
        "        self.embeddings = nn.Embedding(text.vocab.vectors.size()[0], text.vocab.vectors.size()[1])\n",
        "        self.embeddings.weight.data.copy_(text.vocab.vectors)\n",
        "        self.linear = nn.Linear(input_size+1, num_classes, bias = True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x, lengths = x\n",
        "        lengths = Variable(lengths.view(-1, 1).float())\n",
        "        embedded = self.embeddings(x)\n",
        "        average_embed = embedded.mean(0)\n",
        "        concat = torch.cat([average_embed, lengths], dim = 1) # add lengths as a feature\n",
        "        output = self.linear(concat)\n",
        "        logits = nn.functional.log_softmax(output, dim = 1)\n",
        "        return logits\n",
        "\n",
        "    def predict(self, x):\n",
        "        logits = self.forward(x)\n",
        "        return logits.max(1)[1] + 1\n",
        "    \n",
        "    def train(self, train_iter, val_iter, test_iter, num_epochs, learning_rate = 1e-3, plot = False):\n",
        "        criterion = nn.NLLLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "        loss_vec = []\n",
        "        \n",
        "        for epoch in tqdm(range(1, num_epochs + 1)):\n",
        "            epoch_loss = 0\n",
        "            for batch in train_iter:\n",
        "                x = batch.text\n",
        "                y = batch.label\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                y_p = self.forward(x)\n",
        "                \n",
        "                loss = criterion(y_p, y-1)\n",
        "                loss.backward()\n",
        "                \n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.data\n",
        "                \n",
        "            self.model = model\n",
        "            \n",
        "            loss_vec.append(epoch_loss / len(train_iter))\n",
        "            if epoch % 1 == 0:\n",
        "                acc = self.validate(val_iter)\n",
        "                print('Epoch {} loss: {} | acc: {}'.format(epoch, loss_vec[epoch-1], acc))\n",
        "                self.model = model\n",
        "                self.test(test_iter)\n",
        "        \n",
        "        if plot:\n",
        "            plt.plot(range(len(loss_vec)), loss_vec)\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "        print('\\nModel trained.\\n')\n",
        "        self.loss_vec = loss_vec\n",
        "        self.model = model\n",
        "\n",
        "    def test(self, test_iter):\n",
        "        \"All models should be able to be run with following command.\"\n",
        "        upload, trues = [], []\n",
        "        # Update: for kaggle the bucket iterator needs to have batch_size 10\n",
        "        for batch in test_iter:\n",
        "            # Your prediction data here (don't cheat!)\n",
        "            x, y = batch.text, batch.label\n",
        "            preds = self.predict(x)\n",
        "            upload += list(preds.data.numpy())\n",
        "            trues += list(y.data.numpy())\n",
        "            \n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(upload, trues)])\n",
        "        accuracy = float(correct) / len(trues)\n",
        "        print('Test Accuracy:', accuracy)\n",
        "\n",
        "        with open(\"predictions.txt\", \"w\") as f:\n",
        "            for u in upload:\n",
        "                f.write(str(u) + \"\\n\")\n",
        "                \n",
        "    def validate(self, val_iter):\n",
        "        y_p, y_t, correct = [], [], 0\n",
        "        for batch in val_iter:\n",
        "            x, y = batch.text, batch.label\n",
        "            probs = self.model.predict(x)[:len(y.data.numpy())]\n",
        "            y_p += list(probs.data.numpy())\n",
        "            y_t += list(y.data.numpy())\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(y_p, y_t)])\n",
        "        accuracy = float(correct) / len(y_p)\n",
        "        return accuracy\n",
        "\n",
        "text = torchtext.data.Field(include_lengths = True)\n",
        "label = torchtext.data.Field(sequential=False)\n",
        "train, val, test = torchtext.datasets.SST.splits(text, label, filter_pred=lambda ex: ex.label != 'neutral')\n",
        "text.build_vocab(train)\n",
        "label.build_vocab(train)\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=10, device=-1, repeat = False)\n",
        "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec'\n",
        "text.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))\n",
        "\n",
        "model = CBoW(input_size = 300, num_classes = 2, batch_size = 10)\n",
        "model.train(train_iter = train_iter, val_iter = val_iter, test_iter = test_iter, num_epochs = 25, learning_rate = 1e-4, plot = False)\n",
        "model.test(test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  4%|▍         | 1/25 [00:33<13:27, 33.63s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 loss: 0.7168439030647278 | acc: 0.5412844036697247\n",
            "Test Accuracy: 0.5145524437122461\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  8%|▊         | 2/25 [01:09<13:09, 34.32s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2 loss: 0.6814231872558594 | acc: 0.551605504587156\n",
            "Test Accuracy: 0.5420098846787479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▏        | 3/25 [01:45<12:45, 34.81s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3 loss: 0.6659574508666992 | acc: 0.6513761467889908\n",
            "Test Accuracy: 0.6337177375068643\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 16%|█▌        | 4/25 [02:21<12:16, 35.08s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4 loss: 0.6430544257164001 | acc: 0.6915137614678899\n",
            "Test Accuracy: 0.6825919824272377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 5/25 [02:56<11:43, 35.16s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5 loss: 0.6133494973182678 | acc: 0.7259174311926605\n",
            "Test Accuracy: 0.7111477210323998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 24%|██▍       | 6/25 [03:32<11:14, 35.49s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6 loss: 0.5797777771949768 | acc: 0.7350917431192661\n",
            "Test Accuracy: 0.7237781438769907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 28%|██▊       | 7/25 [04:08<10:38, 35.48s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7 loss: 0.5425764918327332 | acc: 0.7454128440366973\n",
            "Test Accuracy: 0.7380560131795717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 32%|███▏      | 8/25 [04:43<10:02, 35.45s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 loss: 0.503654956817627 | acc: 0.7568807339449541\n",
            "Test Accuracy: 0.7495881383855024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 36%|███▌      | 9/25 [05:18<09:25, 35.35s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9 loss: 0.4707545042037964 | acc: 0.7626146788990825\n",
            "Test Accuracy: 0.7622185612300933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 10/25 [05:54<08:50, 35.36s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10 loss: 0.4347337484359741 | acc: 0.7637614678899083\n",
            "Test Accuracy: 0.7726523887973641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 44%|████▍     | 11/25 [06:29<08:14, 35.33s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 11 loss: 0.4026670455932617 | acc: 0.7637614678899083\n",
            "Test Accuracy: 0.7775947281713345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 48%|████▊     | 12/25 [07:04<07:39, 35.38s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 12 loss: 0.37324756383895874 | acc: 0.7626146788990825\n",
            "Test Accuracy: 0.7814387699066447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 52%|█████▏    | 13/25 [07:40<07:03, 35.33s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 13 loss: 0.34554803371429443 | acc: 0.768348623853211\n",
            "Test Accuracy: 0.7896760021965953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 56%|█████▌    | 14/25 [08:15<06:27, 35.22s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 14 loss: 0.3194361627101898 | acc: 0.7786697247706422\n",
            "Test Accuracy: 0.7984623833058759\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 15/25 [08:50<05:51, 35.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 15 loss: 0.2952537536621094 | acc: 0.7763761467889908\n",
            "Test Accuracy: 0.7990115321252059\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 64%|██████▍   | 16/25 [09:25<05:16, 35.18s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 16 loss: 0.27366629242897034 | acc: 0.7740825688073395\n",
            "Test Accuracy: 0.8039538714991763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 68%|██████▊   | 17/25 [10:00<04:41, 35.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 17 loss: 0.2549130320549011 | acc: 0.7763761467889908\n",
            "Test Accuracy: 0.8083470620538166\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 72%|███████▏  | 18/25 [10:35<04:06, 35.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 18 loss: 0.23779645562171936 | acc: 0.7798165137614679\n",
            "Test Accuracy: 0.8099945085118067\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 76%|███████▌  | 19/25 [11:11<03:31, 35.26s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 19 loss: 0.21841135621070862 | acc: 0.7775229357798165\n",
            "Test Accuracy: 0.8088962108731467\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 20/25 [11:46<02:56, 35.24s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 20 loss: 0.2020738422870636 | acc: 0.7763761467889908\n",
            "Test Accuracy: 0.8105436573311368\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 84%|████████▍ | 21/25 [12:22<02:21, 35.35s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 21 loss: 0.1885262429714203 | acc: 0.7763761467889908\n",
            "Test Accuracy: 0.8110928061504667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 88%|████████▊ | 22/25 [12:57<01:45, 35.30s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 22 loss: 0.1769775003194809 | acc: 0.7752293577981652\n",
            "Test Accuracy: 0.8138385502471169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 92%|█████████▏| 23/25 [13:33<01:11, 35.61s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 23 loss: 0.16404668986797333 | acc: 0.7775229357798165\n",
            "Test Accuracy: 0.8116419549697969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 96%|█████████▌| 24/25 [14:09<00:35, 35.59s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 24 loss: 0.15179432928562164 | acc: 0.7740825688073395\n",
            "Test Accuracy: 0.8138385502471169\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 25/25 [14:44<00:00, 35.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 25 loss: 0.141509011387825 | acc: 0.7763761467889908\n",
            "Test Accuracy: 0.814387699066447\n",
            "\n",
            "Model trained.\n",
            "\n",
            "Test Accuracy: 0.814387699066447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLljUqA0ISfu",
        "colab_type": "code",
        "outputId": "7fe14593-57fe-453b-d6a8-9ebc574ee19f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from torchtext.vocab import Vectors\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, batch_size):\n",
        "        super(CNN, self).__init__()\n",
        "        self.embeddings = nn.Embedding(text.vocab.vectors.size()[0], text.vocab.vectors.size()[1])\n",
        "        self.embeddings.weight.data.copy_(text.vocab.vectors)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = in_channels, out_channels = in_channels, kernel_size = n) for n in (1,2,3,4)])\n",
        "        self.dropout_train, self.dropout_test = nn.Dropout(p = 0.5), nn.Dropout(p = 0)\n",
        "        self.linear = nn.Linear(in_features=in_channels, out_features=out_channels, bias = True)\n",
        "    \n",
        "    def forward(self, x, train = True):\n",
        "        embedded = self.embeddings(x)\n",
        "        embedded = embedded.transpose(1, 2)\n",
        "        embedded = embedded.transpose(0, 2)\n",
        "        concatted_features = torch.cat([conv(embedded) for conv in self.convs if embedded.size(2) >= conv.kernel_size[0]], dim = 2)\n",
        "        activated_features = nn.functional.relu(concatted_features)\n",
        "        pooled = nn.functional.max_pool1d(activated_features, activated_features.size(2)).squeeze(2)\n",
        "        dropped = self.dropout_train(pooled) if train else self.dropout_test(pooled)\n",
        "        output = self.linear(dropped)\n",
        "        logits = nn.functional.log_softmax(output, dim = 1)\n",
        "        return logits\n",
        "\n",
        "    def predict(self, x):\n",
        "        logits = self.forward(x, train = False)\n",
        "        return logits.max(1)[1] + 1\n",
        "    \n",
        "    def train(self, train_iter, val_iter, test_iter, num_epochs, learning_rate = 1e-3, plot = False):\n",
        "        criterion = nn.NLLLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "        loss_vec = []\n",
        "        \n",
        "        for epoch in tqdm(range(1, num_epochs+1)):\n",
        "            epoch_loss = 0\n",
        "            for batch in train_iter:\n",
        "                x = batch.text\n",
        "                y = batch.label\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                y_p = self.forward(x)\n",
        "                \n",
        "                loss = criterion(y_p, y-1)\n",
        "                loss.backward()\n",
        "                \n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.data\n",
        "                \n",
        "            self.model = model\n",
        "            \n",
        "            loss_vec.append(epoch_loss / len(train_iter))\n",
        "            if epoch % 1 == 0:\n",
        "                acc = self.validate(val_iter)\n",
        "                print('Epoch {} loss: {} | acc: {}'.format(epoch, loss_vec[epoch-1], acc))\n",
        "                self.model = model\n",
        "                self.test(test_iter)\n",
        "\n",
        "        if plot:\n",
        "            plt.plot(range(len(loss_vec)), loss_vec)\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "        \n",
        "        print('\\nModel trained.\\n')\n",
        "        self.loss_vec = loss_vec\n",
        "        self.model = model\n",
        "\n",
        "    def test(self, test_iter):\n",
        "        \"All models should be able to be run with following command.\"\n",
        "        upload, trues = [], []\n",
        "        # Update: for kaggle the bucket iterator needs to have batch_size 10\n",
        "        for batch in test_iter:\n",
        "            # Your prediction data here (don't cheat!)\n",
        "            x, y = batch.text, batch.label\n",
        "            probs = self.predict(x)\n",
        "            upload += list(probs.data)\n",
        "            trues += list(y.data)\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(upload, trues)])\n",
        "        accuracy = float(correct) / len(trues)\n",
        "        print('Testset Accuracy:', accuracy)\n",
        "\n",
        "        with open(\"predictions.txt\", \"w\") as f:\n",
        "            for u in upload:\n",
        "                f.write(str(u) + \"\\n\")\n",
        "                \n",
        "    def validate(self, val_iter):\n",
        "        y_p, y_t, correct = [], [], 0\n",
        "        for batch in val_iter:\n",
        "            x, y = batch.text, batch.label\n",
        "            probs = self.model.predict(x)[:len(y)]\n",
        "            y_p += list(probs.data)\n",
        "             \n",
        "            y_t += list(y.data)\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(y_p, y_t)])\n",
        "        accuracy = float(correct) / len(y_p)\n",
        "        return accuracy\n",
        "\n",
        "text = torchtext.data.Field(include_lengths = False)\n",
        "label = torchtext.data.Field(sequential=False)\n",
        "train, val, test = torchtext.datasets.SST.splits(text, label, filter_pred=lambda ex: ex.label != 'neutral')\n",
        "text.build_vocab(train)\n",
        "label.build_vocab(train)\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=10, device=-1, repeat = False)\n",
        "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec'\n",
        "text.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))\n",
        "\n",
        "model = CNN(in_channels = 300, out_channels = 2, batch_size = 10)\n",
        "model.train(train_iter = train_iter, val_iter = val_iter, test_iter = test_iter, num_epochs = 24, learning_rate = 1e-4)\n",
        "model.test(test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "  0%|          | 0/24 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 loss: 0.6650628447532654 | acc: 0.6857798165137615\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  4%|▍         | 1/24 [01:21<31:22, 81.84s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.6880834706205382\n",
            "Epoch 2 loss: 0.582319438457489 | acc: 0.7465596330275229\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 2/24 [02:45<30:14, 82.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7512355848434926\n",
            "Epoch 3 loss: 0.49427539110183716 | acc: 0.7580275229357798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▎        | 3/24 [04:09<29:01, 82.91s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7611202635914333\n",
            "Epoch 4 loss: 0.4141438603401184 | acc: 0.7706422018348624\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 17%|█▋        | 4/24 [05:33<27:44, 83.25s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7891268533772653\n",
            "Epoch 5 loss: 0.34017038345336914 | acc: 0.7672018348623854\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 21%|██        | 5/24 [06:56<26:20, 83.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7957166392092258\n",
            "Epoch 6 loss: 0.2809557318687439 | acc: 0.7855504587155964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 6/24 [08:23<25:17, 84.31s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8061504667764964\n",
            "Epoch 7 loss: 0.22486960887908936 | acc: 0.7901376146788991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 29%|██▉       | 7/24 [09:48<23:54, 84.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8083470620538166\n",
            "Epoch 8 loss: 0.17544494569301605 | acc: 0.786697247706422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 8/24 [11:12<22:28, 84.29s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8072487644151565\n",
            "Epoch 9 loss: 0.13156643509864807 | acc: 0.7901376146788991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 9/24 [12:36<21:03, 84.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8127402526084568\n",
            "Epoch 10 loss: 0.0995393767952919 | acc: 0.7912844036697247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 42%|████▏     | 10/24 [14:00<19:39, 84.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.814936847885777\n",
            "Epoch 11 loss: 0.07126346975564957 | acc: 0.7981651376146789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 46%|████▌     | 11/24 [15:24<18:12, 84.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8094453596924767\n",
            "Epoch 12 loss: 0.050339046865701675 | acc: 0.7935779816513762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 12/24 [16:48<16:50, 84.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8088962108731467\n",
            "Epoch 13 loss: 0.03466447442770004 | acc: 0.7958715596330275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 54%|█████▍    | 13/24 [18:16<15:37, 85.24s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8121911037891268\n",
            "Epoch 14 loss: 0.02728523127734661 | acc: 0.7878440366972477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 58%|█████▊    | 14/24 [19:42<14:13, 85.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8072487644151565\n",
            "Epoch 15 loss: 0.018109498545527458 | acc: 0.7947247706422018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 62%|██████▎   | 15/24 [21:07<12:48, 85.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8116419549697969\n",
            "Epoch 16 loss: 0.012813574634492397 | acc: 0.7912844036697247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 16/24 [22:32<11:22, 85.35s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8099945085118067\n",
            "Epoch 17 loss: 0.009893606416881084 | acc: 0.7878440366972477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 71%|███████   | 17/24 [23:58<09:58, 85.43s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8094453596924767\n",
            "Epoch 18 loss: 0.006835313979536295 | acc: 0.7889908256880734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 18/24 [25:23<08:31, 85.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8039538714991763\n",
            "Epoch 19 loss: 0.005119462497532368 | acc: 0.7889908256880734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 79%|███████▉  | 19/24 [26:47<07:04, 85.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8023064250411862\n",
            "Epoch 20 loss: 0.003451312892138958 | acc: 0.7889908256880734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 83%|████████▎ | 20/24 [28:12<05:39, 84.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8045030203185063\n",
            "Epoch 21 loss: 0.0029747916851192713 | acc: 0.7889908256880734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 21/24 [29:37<04:14, 84.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8012081274025261\n",
            "Epoch 22 loss: 0.0020421422086656094 | acc: 0.7935779816513762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 22/24 [31:02<02:49, 84.95s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8028555738605162\n",
            "Epoch 23 loss: 0.001434191013686359 | acc: 0.7935779816513762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 23/24 [32:27<01:24, 84.96s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7946183415705657\n",
            "Epoch 24 loss: 0.0009995477739721537 | acc: 0.7889908256880734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [33:52<00:00, 84.67s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7968149368478857\n",
            "\n",
            "Model trained.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7968149368478857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eciwp5AgWzQR",
        "colab_type": "code",
        "outputId": "51bc5b58-6c7c-49f7-fc9a-b153979e7c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "import torchtext\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from torchtext.vocab import Vectors\n",
        "from tqdm import tqdm\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, batch_size):\n",
        "        super(CNN, self).__init__()\n",
        "        self.embeddings = nn.Embedding(text.vocab.vectors.size()[0], text.vocab.vectors.size()[1])\n",
        "        self.embeddings.weight.data.copy_(text.vocab.vectors)\n",
        "        self.convs = nn.ModuleList([nn.Conv1d(in_channels = in_channels, out_channels = in_channels, kernel_size = n) for n in (1,2,3,4)])\n",
        "        self.dropout_train, self.dropout_test = nn.Dropout(p = 0.5), nn.Dropout(p = 0)\n",
        "        self.linear = nn.Linear(in_features=in_channels, out_features=out_channels, bias = True)\n",
        "    \n",
        "    def forward(self, x, train = True):\n",
        "        embedded = self.embeddings(x)\n",
        "        embedded = embedded.transpose(1, 2)\n",
        "        embedded = embedded.transpose(0, 2)\n",
        "        concatted_features = torch.cat([conv(embedded) for conv in self.convs if embedded.size(2) >= conv.kernel_size[0]], dim = 2)\n",
        "        activated_features = nn.functional.relu(concatted_features)\n",
        "        pooled = nn.functional.max_pool1d(activated_features, activated_features.size(2)).squeeze(2)\n",
        "        dropped = self.dropout_train(pooled) if train else self.dropout_test(pooled)\n",
        "        output = self.linear(dropped)\n",
        "        logits = nn.functional.log_softmax(output, dim = 1)\n",
        "        return logits\n",
        "\n",
        "    def predict(self, x):\n",
        "        logits = self.forward(x, train = False)\n",
        "        return logits.max(1)[1] + 1\n",
        "    \n",
        "    def train(self, train_iter, val_iter, test_iter, num_epochs, learning_rate = 1e-3, plot = False):\n",
        "        criterion = nn.NLLLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "        loss_vec = []\n",
        "        \n",
        "        for epoch in tqdm(range(1, num_epochs+1)):\n",
        "            epoch_loss = 0\n",
        "            for batch in train_iter:\n",
        "                x = batch.text\n",
        "                y = batch.label\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                \n",
        "                y_p = self.forward(x)\n",
        "                \n",
        "                loss = criterion(y_p, y-1)\n",
        "                loss.backward()\n",
        "                \n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.data\n",
        "                \n",
        "            self.model = model\n",
        "            \n",
        "            loss_vec.append(epoch_loss / len(train_iter))\n",
        "            if epoch % 1 == 0:\n",
        "                acc = self.validate(val_iter)\n",
        "                print('Epoch {} loss: {} | acc: {}'.format(epoch, loss_vec[epoch-1], acc))\n",
        "                self.model = model\n",
        "                self.test(test_iter)\n",
        "\n",
        "        if plot:\n",
        "            plt.plot(range(len(loss_vec)), loss_vec)\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "        \n",
        "        print('\\nModel trained.\\n')\n",
        "        self.loss_vec = loss_vec\n",
        "        self.model = model\n",
        "\n",
        "    def test(self, test_iter):\n",
        "        \"All models should be able to be run with following command.\"\n",
        "        upload, trues = [], []\n",
        "        # Update: for kaggle the bucket iterator needs to have batch_size 10\n",
        "        for batch in test_iter:\n",
        "            # Your prediction data here (don't cheat!)\n",
        "            x, y = batch.text, batch.label\n",
        "            probs = self.predict(x)\n",
        "            upload += list(probs.data)\n",
        "            trues += list(y.data)\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(upload, trues)])\n",
        "        accuracy = float(correct) / len(trues)\n",
        "        print('Testset Accuracy:', accuracy)\n",
        "\n",
        "        with open(\"predictions.txt\", \"w\") as f:\n",
        "            for u in upload:\n",
        "                f.write(str(u) + \"\\n\")\n",
        "                \n",
        "    def validate(self, val_iter):\n",
        "        y_p, y_t, correct = [], [], 0\n",
        "        for batch in val_iter:\n",
        "            x, y = batch.text, batch.label\n",
        "            probs = self.model.predict(x)[:len(y)]\n",
        "            y_p += list(probs.data)\n",
        "             \n",
        "            y_t += list(y.data)\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(y_p, y_t)])\n",
        "        accuracy = float(correct) / len(y_p)\n",
        "        return accuracy\n",
        "\n",
        "text = torchtext.data.Field(include_lengths = False)\n",
        "label = torchtext.data.Field(sequential=False)\n",
        "train, val, test = torchtext.datasets.SST.splits(text, label, filter_pred=lambda ex: ex.label != 'neutral')\n",
        "text.build_vocab(train)\n",
        "label.build_vocab(train)\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=10, device=-1, repeat = False)\n",
        "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec'\n",
        "text.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))\n",
        "\n",
        "model = CNN(in_channels = 300, out_channels = 2, batch_size = 10)\n",
        "model.train(train_iter = train_iter, val_iter = val_iter, test_iter = test_iter, num_epochs = 15, learning_rate = 1e-4)\n",
        "model.test(test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "\n",
            "  0%|          | 0/15 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 loss: 0.6653319597244263 | acc: 0.7178899082568807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  7%|▋         | 1/15 [01:18<18:25, 78.97s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7364085667215815\n",
            "Epoch 2 loss: 0.5812797546386719 | acc: 0.7259174311926605\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 13%|█▎        | 2/15 [02:39<17:14, 79.58s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7259747391543108\n",
            "Epoch 3 loss: 0.49230268597602844 | acc: 0.7557339449541285\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 3/15 [04:01<16:00, 80.06s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7660626029654036\n",
            "Epoch 4 loss: 0.41089633107185364 | acc: 0.7534403669724771\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 27%|██▋       | 4/15 [05:23<14:47, 80.68s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7775947281713345\n",
            "Epoch 5 loss: 0.344173401594162 | acc: 0.7752293577981652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|███▎      | 5/15 [06:45<13:32, 81.21s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7946183415705657\n",
            "Epoch 6 loss: 0.2796323597431183 | acc: 0.7809633027522935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 6/15 [08:10<12:20, 82.31s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8017572762218561\n",
            "Epoch 7 loss: 0.2229406088590622 | acc: 0.7878440366972477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 47%|████▋     | 7/15 [09:32<10:57, 82.19s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8083470620538166\n",
            "Epoch 8 loss: 0.172508105635643 | acc: 0.7924311926605505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 53%|█████▎    | 8/15 [10:54<09:34, 82.03s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8083470620538166\n",
            "Epoch 9 loss: 0.13146154582500458 | acc: 0.7970183486238532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 9/15 [12:15<08:11, 81.93s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8083470620538166\n",
            "Epoch 10 loss: 0.09439703077077866 | acc: 0.7821100917431193\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|██████▋   | 10/15 [13:37<06:48, 81.75s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.7984623833058759\n",
            "Epoch 11 loss: 0.07060116529464722 | acc: 0.7901376146788991\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 73%|███████▎  | 11/15 [14:58<05:26, 81.66s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8110928061504667\n",
            "Epoch 12 loss: 0.050444599241018295 | acc: 0.7993119266055045\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 12/15 [16:20<04:04, 81.59s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8072487644151565\n",
            "Epoch 13 loss: 0.03496059775352478 | acc: 0.7970183486238532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 87%|████████▋ | 13/15 [17:41<02:43, 81.60s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8116419549697969\n",
            "Epoch 14 loss: 0.025711454451084137 | acc: 0.7981651376146789\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 93%|█████████▎| 14/15 [19:05<01:22, 82.17s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8099945085118067\n",
            "Epoch 15 loss: 0.019895847886800766 | acc: 0.7947247706422018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 15/15 [20:26<00:00, 81.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8083470620538166\n",
            "\n",
            "Model trained.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testset Accuracy: 0.8083470620538166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qyulKO6B_R8",
        "colab_type": "code",
        "outputId": "28319493-fc16-45b8-f16a-5c7d4d586fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "308f34cdc20740a9a7a6753a607c13bf",
            "52c80329c11644eb89858a898cef6f1e",
            "7260e324e6484b30b9df3e636cd30d71",
            "11c89344126b42b1af81662a440c6f2e",
            "ed52591f76a84eb3b9e0f482824d96b5",
            "1f7c553a28a046de9f7aacca9b2dae5d",
            "d96bdb3f6b7b45d396ec5f3cefc2e1d2",
            "c310001a6d134c999fc4985fe2162634"
          ]
        }
      },
      "source": [
        "''' CNN with conv2D '''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchtext.vocab import Vectors\n",
        "import torchtext\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "label = torchtext.data.Field(sequential=False)\n",
        "train, val, test = torchtext.datasets.SST.splits(text, label, filter_pred=lambda ex: ex.label != 'neutral')\n",
        "text.build_vocab(train)\n",
        "label.build_vocab(train)\n",
        "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits((train, val, test), batch_size=10, device=-1, repeat = False)\n",
        "url = 'https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.simple.vec'\n",
        "text.vocab.load_vectors(vectors=Vectors('wiki.simple.vec', url=url))\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, batch_size):\n",
        "        super(CNN, self).__init__()\n",
        "        self.embeddings = nn.Embedding(text.vocab.vectors.size()[0], text.vocab.vectors.size()[1])\n",
        "        self.embeddings.weight.data.copy_(text.vocab.vectors)\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(1, 100, (n, text.vocab.vectors.shape[1])) for n in (3,4,5)])        \n",
        "        self.dropout_train, self.dropout_test = nn.Dropout(p = 0.5), nn.Dropout(p = 0)\n",
        "        self.linear = nn.Linear(in_features=in_channels, out_features=out_channels, bias = True)\n",
        "    \n",
        "    def forward(self, x, train = True):\n",
        "        embedded = self.embeddings(x)\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        convolved = [nn.functional.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "        pooled = [nn.functional.max_pool1d(convd, convd.size(2)).squeeze(2) for convd in convolved]\n",
        "        concatted = torch.cat(pooled, 1)\n",
        "        dropped = self.dropout_train(concatted) if train else self.dropout_test(concatted)\n",
        "        output = self.linear(dropped)\n",
        "        logits = nn.functional.log_softmax(output, dim = 1)\n",
        "        return logits\n",
        "\n",
        "    def predict(self, x):\n",
        "        logits = self.forward(x, train = False)\n",
        "        return logits.max(1)[1] + 1\n",
        "    \n",
        "    def train(self, train_iter, val_iter, num_epochs, learning_rate = 1e-3):\n",
        "        criterion = nn.NLLLoss()\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "        loss_vec = []\n",
        "        \n",
        "        for epoch in tqdm_notebook(range(1, num_epochs+1)):\n",
        "            epoch_loss = 0\n",
        "            for batch in train_iter:\n",
        "                x = batch.text\n",
        "                y = batch.label\n",
        "                \n",
        "                optimizer.zero_grad()\n",
        "                y_p = self.forward(x)\n",
        "                \n",
        "                loss = criterion(y_p, y-1)\n",
        "                loss.backward()\n",
        "                \n",
        "                optimizer.step()\n",
        "                epoch_loss += loss.data\n",
        "                \n",
        "            self.model = model\n",
        "            \n",
        "            loss_vec.append(epoch_loss / len(train_iter))\n",
        "            if epoch % 1 == 0:\n",
        "                acc = self.validate(val_iter)\n",
        "                print('Epoch {} loss: {} | acc: {}'.format(epoch, loss_vec[epoch-1], acc))\n",
        "                self.model = model\n",
        "        \n",
        "        plt.plot(range(len(loss_vec)), loss_vec)\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.show()\n",
        "        print('\\nModel trained.\\n')\n",
        "        self.loss_vec = loss_vec\n",
        "        self.model = model\n",
        "\n",
        "    def test(self, test_iter):\n",
        "        \"All models should be able to be run with following command.\"\n",
        "        upload, trues = [], []\n",
        "        # Update: for kaggle the bucket iterator needs to have batch_size 10\n",
        "        for batch in test_iter:\n",
        "            # Your prediction data here (don't cheat!)\n",
        "            x, y = batch.text, batch.label\n",
        "            probs = self.predict(x)[:len(y)]\n",
        "            upload += list(probs.data)\n",
        "            trues += list(y.data)\n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(upload, trues)])\n",
        "        accuracy = correct / len(trues)\n",
        "        print('Testset Accuracy:', accuracy)\n",
        "\n",
        "        with open(\"predictions.txt\", \"w\") as f:\n",
        "            for u in upload:\n",
        "                f.write(str(u) + \"\\n\")\n",
        "                \n",
        "    def validate(self, val_iter):\n",
        "        y_p, y_t, correct = [], [], 0\n",
        "        for batch in val_iter:\n",
        "            x, y = batch.text, batch.label\n",
        "            probs = self.predict(x)[:len(y)]\n",
        "            y_p += list(probs.data) \n",
        "            y_t += list(y.data)\n",
        "            \n",
        "        correct = sum([1 if i == j else 0 for i, j in zip(y_p, y_t)])\n",
        "        accuracy = correct / len(y_p)\n",
        "        return accuracy\n",
        "\n",
        "model = CNN(in_channels = 300, out_channels = 2, batch_size = 10)\n",
        "model.train(train_iter = train_iter, val_iter = test_iter, num_epochs = 25, learning_rate = 1e-4)\n",
        "model.test(test_iter)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:48: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "308f34cdc20740a9a7a6753a607c13bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-823ffa4e14d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-823ffa4e14d4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_iter, val_iter, num_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0my_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 2113\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   2114\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2115\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (39) to match target batch_size (10)."
          ]
        }
      ]
    }
  ]
}